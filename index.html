<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>HLSF Cognition Engine v1.0</title>
  <style>
    :root {
      color-scheme: dark;
      --bg: #0a0a0a;
      --panel: #111;
      --text: #e0e0e0;
      --accent: #00ff88;
      --error: #ff4444;
      --success: #44ff44;
      --medium: #ffd54f;
      --low: #ff7777;
      --scrollbar: #1f1f1f;
    }

    * {
      box-sizing: border-box;
    }

    body {
      margin: 0;
      font-family: 'Fira Code', Consolas, Monaco, 'Courier New', monospace;
      background: var(--bg);
      color: var(--text);
      min-height: 100vh;
      display: flex;
      flex-direction: column;
    }

    #app {
      flex: 1;
      display: flex;
      flex-direction: column;
      max-width: 1200px;
      margin: 0 auto;
      padding: 1.5rem;
      width: 100%;
    }

    #header {
      font-size: 1.3rem;
      font-weight: bold;
      margin-bottom: 1rem;
      color: var(--accent);
      display: flex;
      align-items: center;
      justify-content: space-between;
    }

    #log {
      flex: 1;
      background: var(--panel);
      border: 1px solid #222;
      border-radius: 12px;
      padding: 1rem;
      overflow-y: auto;
      display: flex;
      flex-direction: column;
      gap: 1rem;
      box-shadow: 0 0 20px rgba(0, 255, 136, 0.1);
    }

    #log::-webkit-scrollbar {
      width: 10px;
    }

    #log::-webkit-scrollbar-thumb {
      background: var(--scrollbar);
      border-radius: 10px;
    }

    #input-area {
      margin-top: 1rem;
      display: flex;
      gap: 0.75rem;
    }

    #command-input {
      flex: 1;
      padding: 0.75rem 1rem;
      background: var(--panel);
      border: 1px solid #222;
      border-radius: 8px;
      color: var(--text);
      font-size: 1rem;
      transition: border 0.2s ease-in-out, box-shadow 0.2s ease-in-out;
    }

    #command-input:focus {
      outline: none;
      border-color: var(--accent);
      box-shadow: 0 0 0 2px rgba(0, 255, 136, 0.2);
    }

    #send-btn {
      padding: 0.75rem 1.5rem;
      border: none;
      border-radius: 8px;
      font-size: 1rem;
      background: var(--accent);
      color: #022d15;
      font-weight: bold;
      cursor: pointer;
      transition: transform 0.15s ease, box-shadow 0.15s ease;
    }

    #send-btn:hover {
      transform: translateY(-1px);
      box-shadow: 0 10px 25px rgba(0, 255, 136, 0.25);
    }

    #send-btn:disabled {
      opacity: 0.6;
      cursor: not-allowed;
      box-shadow: none;
      transform: none;
    }

    .log-entry {
      border-left: 3px solid var(--accent);
      padding-left: 1rem;
      animation: fadeIn 0.3s ease;
    }

    .log-entry .timestamp {
      font-size: 0.75rem;
      opacity: 0.6;
    }

    .log-entry.status {
      font-style: italic;
    }

    .log-entry.error {
      border-left-color: var(--error);
      color: var(--error);
    }

    .log-entry.success {
      border-left-color: var(--success);
      color: var(--success);
    }

    details {
      background: rgba(255, 255, 255, 0.02);
      border: 1px solid #222;
      border-radius: 8px;
      padding: 0.5rem 0.75rem;
      transition: border 0.2s ease;
    }

    details[open] {
      border-color: var(--accent);
      box-shadow: 0 0 0 1px rgba(0, 255, 136, 0.25);
    }

    summary {
      cursor: pointer;
      display: flex;
      align-items: center;
      gap: 0.5rem;
      list-style: none;
      font-weight: 600;
    }

    summary::-webkit-details-marker {
      display: none;
    }

    .status-badge {
      font-size: 0.75rem;
      padding: 0.1rem 0.35rem;
      border-radius: 999px;
      background: rgba(255, 255, 255, 0.08);
      color: var(--text);
    }

    .token-entry {
      margin-top: 0.5rem;
      display: grid;
      gap: 0.35rem;
    }

    .token-entry pre {
      margin: 0;
      padding: 0.75rem;
      background: rgba(255, 255, 255, 0.02);
      border-radius: 8px;
      overflow-x: auto;
      font-size: 0.9rem;
      line-height: 1.5;
      border: 1px solid rgba(0, 255, 136, 0.1);
    }

    .json-key {
      color: #64b5f6;
    }

    .json-string {
      color: #f48fb1;
    }

    .json-number {
      color: #ffb74d;
    }

    .json-boolean {
      color: #81c784;
    }

    .attention-badge {
      font-weight: bold;
      padding: 0.15rem 0.45rem;
      border-radius: 999px;
      color: #011;
    }

    .attention-high {
      background: #00ff88;
    }

    .attention-medium {
      background: #ffd54f;
    }

    .attention-low {
      background: #ff7777;
    }

    .attention-hub {
      background: #4aa3ff;
      color: #021226;
    }

    .attention-bridge {
      background: #bf7fff;
      color: #220031;
    }

    .modal {
      position: fixed;
      inset: 0;
      backdrop-filter: blur(8px);
      background: rgba(0, 0, 0, 0.7);
      display: flex;
      align-items: center;
      justify-content: center;
      z-index: 999;
    }

    .modal.hidden {
      display: none;
    }

    .modal-content {
      background: #111;
      border: 1px solid var(--accent);
      border-radius: 12px;
      padding: 2rem;
      width: min(420px, 90vw);
      display: flex;
      flex-direction: column;
      gap: 1rem;
      box-shadow: 0 20px 40px rgba(0, 0, 0, 0.4);
    }

    .modal-content h2 {
      margin: 0;
      color: var(--accent);
    }

    .modal-content input {
      padding: 0.75rem 1rem;
      border-radius: 8px;
      border: 1px solid #222;
      background: #0c0c0c;
      color: var(--text);
      font-size: 1rem;
    }

    .modal-actions {
      display: flex;
      justify-content: flex-end;
      gap: 0.75rem;
    }

    .pill-button {
      border-radius: 999px;
      border: none;
      padding: 0.5rem 1.4rem;
      font-weight: bold;
      cursor: pointer;
      transition: transform 0.15s ease, box-shadow 0.15s ease;
    }

    .pill-button.primary {
      background: var(--accent);
      color: #022d15;
    }

    .pill-button.secondary {
      background: transparent;
      border: 1px solid #333;
      color: var(--text);
    }

    .pill-button:disabled {
      opacity: 0.6;
      cursor: not-allowed;
      transform: none;
      box-shadow: none;
    }

    .pill-button:not(:disabled):hover {
      transform: translateY(-1px);
      box-shadow: 0 10px 25px rgba(0, 255, 136, 0.18);
    }

    .hidden {
      display: none;
    }

    .processing-indicator {
      display: inline-flex;
      align-items: center;
      gap: 0.35rem;
    }

    .spinner {
      width: 14px;
      height: 14px;
      border-radius: 50%;
      border: 2px solid rgba(0, 255, 136, 0.15);
      border-top-color: var(--accent);
      animation: spin 0.8s linear infinite;
    }

    .status-line {
      display: flex;
      justify-content: space-between;
      align-items: center;
      gap: 0.75rem;
      flex-wrap: wrap;
    }

    .status-line span {
      display: inline-flex;
      align-items: center;
      gap: 0.4rem;
    }

    .status-line small {
      opacity: 0.6;
    }

    .final-output {
      border-left: 3px solid var(--success);
      padding-left: 1rem;
      background: rgba(68, 255, 68, 0.05);
    }

    .final-output h3 {
      margin-top: 0;
      color: var(--success);
    }

    .final-output pre {
      background: rgba(0, 0, 0, 0.35);
      padding: 0.75rem;
      border-radius: 8px;
      overflow-x: auto;
    }

    .final-output details {
      background: rgba(0, 0, 0, 0.2);
      border-color: rgba(0, 255, 136, 0.1);
    }

    .final-output details summary {
      font-weight: 600;
    }

    .output-divider {
      margin: 1rem 0;
      border-bottom: 1px dashed rgba(255, 255, 255, 0.1);
    }

    @media (max-width: 720px) {
      #app {
        padding: 1rem;
      }

      #header {
        flex-direction: column;
        gap: 0.5rem;
        align-items: flex-start;
      }

      #input-area {
        flex-direction: column;
      }

      #send-btn {
        width: 100%;
      }
    }

    @keyframes fadeIn {
      from {
        opacity: 0;
        transform: translateY(6px);
      }
      to {
        opacity: 1;
        transform: translateY(0);
      }
    }

    @keyframes spin {
      from {
        transform: rotate(0deg);
      }
      to {
        transform: rotate(360deg);
      }
    }
  </style>
</head>
<body>
  <div id="api-modal" class="modal">
    <div class="modal-content" role="dialog" aria-modal="true">
      <h2>Enter OpenAI API Key</h2>
      <p>Provide your OpenAI API key (sk-...) to begin using the HLSF Cognition Engine.</p>
      <input id="api-key-input" type="password" placeholder="sk-..." aria-label="OpenAI API key" />
      <div class="modal-actions">
        <button id="api-cancel" class="pill-button secondary">Continue offline</button>
        <button id="api-confirm" class="pill-button primary">Save key</button>
      </div>
      <small style="opacity:0.65">The key is stored only in memory for this session and never persisted.</small>
    </div>
  </div>

  <div id="app" aria-live="polite">
    <div id="header">
      <div>HLSF Cognition Engine v1.0</div>
      <div id="recursion-depth">Recursion depth: <strong>1</strong></div>
    </div>
    <div id="log" aria-label="Command log"></div>
    <div id="input-area">
      <input id="command-input" type="text" placeholder="> Enter a prompt or /command" maxlength="600" autocomplete="off" aria-label="Command input" />
      <button id="send-btn">Send</button>
    </div>
  </div>

  <template id="token-entry-template">
    <details class="token-entry">
      <summary></summary>
      <pre></pre>
    </details>
  </template>

  <script>
    const logContainer = document.getElementById('log');
    const commandInput = document.getElementById('command-input');
    const sendBtn = document.getElementById('send-btn');
    const apiModal = document.getElementById('api-modal');
    const apiKeyInput = document.getElementById('api-key-input');
    const apiConfirmBtn = document.getElementById('api-confirm');
    const apiCancelBtn = document.getElementById('api-cancel');
    const recursionDepthDisplay = document.getElementById('recursion-depth').querySelector('strong');

    let apiKey = '';
    let recursionDepth = 1;
    let isProcessing = false;

    const RELATIONSHIP_PRIORITIES = new Map([
      ['≡', 1.0], ['⊃', 1.0], ['⊂', 0.8], ['≈', 0.7], ['∈', 0.9], ['∋', 0.9],
      ['⊤', 0.9], ['⊥', 0.9], ['⊏', 0.8], ['⊐', 0.8], ['↔', 0.7], ['⇌', 0.7],
      ['∥', 0.6], ['∼', 0.5], ['→', 0.5], ['⇒', 0.5], ['⇐', 0.5], ['↠', 0.5],
      ['↗', 0.4], ['↘', 0.4], ['⇝', 1.0], ['⇂', 0.7], ['≠', 0.8], ['⊕', 0.8],
      ['⊛', 0.7], ['∝', 0.7], ['⇝ Causes', 1.0], ['⇐ Caused By', 0.9],
      ['∗', 0.7], ['≜', 0.9], ['⋆', 0.8], ['7→', 0.7], ['⊢', 0.9], ['⊣', 0.9],
      ['↷', 0.8], ['↶', 0.8], ['◦', 0.9], ['|=', 0.9], ['◁', 0.6], ['⇄', 0.6],
      ['⊗', 0.9], ['÷', 0.7], ['⊘', 0.8], ['×', 0.8], ['¬', 0.8], ['†', 0.8],
      ['⊠', 0.8], ['/∈', 0.8], ['⊬', 0.8], ['⊩', 0.9], ['⊨', 0.9], ['?', 0.5],
      ['⚡', 0.7], ['⇒ Attention', 0.7], ['↶ Self-Reference', 0.7], ['∧', 0.6],
      ['↭', 0.6], ['▷◁', 0.6]
    ]);

    const relationshipPriorityFallback = 0.3;

    function addLogEntry(content, type = 'info') {
      const entry = document.createElement('div');
      entry.className = `log-entry ${type}`;
      const timestamp = new Date().toLocaleTimeString();
      entry.innerHTML = `<div class="timestamp">${timestamp}</div>${content}`;
      logContainer.appendChild(entry);
      logContainer.scrollTo({ top: logContainer.scrollHeight, behavior: 'smooth' });
      return entry;
    }

    function logStatus(message) {
      return addLogEntry(`<div class="processing-indicator"><span class="spinner"></span>${message}</div>`, 'status');
    }

    function logError(message) {
      return addLogEntry(`🔴 ${message}`, 'error');
    }

    function logSuccess(message) {
      return addLogEntry(`✅ ${message}`, 'success');
    }

    function highlightJSON(json) {
      const jsonString = typeof json === 'string' ? json : JSON.stringify(json, null, 2);
      return jsonString
        .replace(/(&)/g, '&amp;')
        .replace(/</g, '&lt;')
        .replace(/>/g, '&gt;')
        .replace(/\"(.*?)\"(?=\s*:)/g, '<span class="json-key">"$1"</span>')
        .replace(/:"(.*?)"/g, ':<span class="json-string">"$1"</span>')
        .replace(/:(\s*)(-?\d+(?:\.\d+)?)/g, ':$1<span class="json-number">$2</span>')
        .replace(/:(\s*)(true|false)/gi, ':$1<span class="json-boolean">$2</span>')
        .replace(/:(\s*)(null)/gi, ':$1<span class="json-boolean">$2</span>');
    }

    function tokenize(text) {
      if (!text) return [];
      return text
        .trim()
        .split(/[^\p{L}\p{N}\-']+/u)
        .filter(Boolean);
    }

    function countTokens(text) {
      return tokenize(text).length;
    }

    function isCommand(input) {
      return input.startsWith('/');
    }

    function commandHelp() {
      addLogEntry(`<strong>Available commands:</strong><br>/clear - clear the log<br>/export - export adjacency matrices<br>/reset - clear stored data<br>/depth [n] - set recursion depth`, 'info');
    }

    apiConfirmBtn.addEventListener('click', () => {
      const key = apiKeyInput.value.trim();
      if (!key.startsWith('sk-')) {
        logError('Invalid API key format. Expected to start with "sk-".');
        return;
      }
      apiKey = key;
      apiModal.classList.add('hidden');
      logSuccess('OpenAI API key stored in memory for this session.');
    });

    apiCancelBtn.addEventListener('click', () => {
      apiKey = '';
      apiModal.classList.add('hidden');
      logError('Proceeding without API key. Live processing will be unavailable.');
    });

    function formatStatusLine(label, detail = '') {
      return `<div class="status-line"><span>${label}</span>${detail ? `<small>${detail}</small>` : ''}</div>`;
    }

    async function handleCommand(command) {
      const [cmd, ...args] = command.slice(1).split(/\s+/);
      switch (cmd.toLowerCase()) {
        case 'clear':
          logContainer.innerHTML = '';
          logSuccess('Command log cleared.');
          break;
        case 'export':
          exportMatrices();
          break;
        case 'reset':
          localStorage.clear();
          logSuccess('All stored adjacency matrices cleared.');
          break;
        case 'depth':
          if (args.length === 0) {
            logError('Usage: /depth [n]');
            break;
          }
          const depth = parseInt(args[0], 10);
          if (Number.isNaN(depth) || depth < 1 || depth > 5) {
            logError('Recursion depth must be an integer between 1 and 5.');
            break;
          }
          recursionDepth = depth;
          recursionDepthDisplay.textContent = depth;
          logSuccess(`Recursion depth set to ${depth}.`);
          break;
        case 'help':
          commandHelp();
          break;
        default:
          logError(`Unknown command: ${cmd}`);
          commandHelp();
      }
    }

    async function fetchOpenAI(messages, options = {}) {
      if (!apiKey) {
        throw new Error('Missing API key. Provide a key to enable API requests.');
      }
      const body = {
        model: options.model ?? 'gpt-4',
        messages,
        max_tokens: options.max_tokens ?? 1000,
        temperature: options.temperature ?? 0.7,
      };
      const maxAttempts = options.retries ?? 3;
      let attempt = 0;
      while (attempt < maxAttempts) {
        attempt += 1;
        const response = await fetch('https://api.openai.com/v1/chat/completions', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            Authorization: `Bearer ${apiKey}`,
          },
          body: JSON.stringify(body),
          signal: options.signal,
        });
        if (response.status === 429 && attempt < maxAttempts) {
          const delay = 500 * Math.pow(2, attempt - 1);
          await new Promise((resolve) => setTimeout(resolve, delay));
          continue;
        }
        if (!response.ok) {
          const errText = await response.text();
          throw new Error(`OpenAI API error (${response.status}): ${errText}`);
        }
        const data = await response.json();
        return data.choices?.[0]?.message?.content?.trim() ?? '';
      }
      throw new Error('OpenAI API request failed after retries.');
    }

    function getLocalAdjacencyKey(token) {
      return `hlsf_token_${token}`;
    }

    function getStoredAdjacency(token) {
      const raw = localStorage.getItem(getLocalAdjacencyKey(token));
      if (!raw) return null;
      try {
        return JSON.parse(raw);
      } catch (err) {
        console.error('Failed to parse adjacency for token', token, err);
        return null;
      }
    }

    function storeAdjacency(token, data) {
      try {
        localStorage.setItem(getLocalAdjacencyKey(token), JSON.stringify(data));
      } catch (err) {
        logError(`Failed to store adjacency for ${token}: ${err.message}`);
      }
    }

    async function requestAdjacency(token, context, signal) {
      const prompt = `Token: "${token}"
Context: "${context}"

For this token, identify the most relevant adjacent tokens across the 50 Pentacognon relationship types. For each relationship type that applies, provide 0-10 related tokens with weights from 0.01 to 1.00.

Relationship types:
≡ Identity, ⊃ Contains, ⊂ Is Contained By, ≈ Variant, ∈ Is Instance Of, ∋ Has Instance, ⊤ Is Type Of, ⊥ Has Type, ⊏ Part Of, ⊐ Composes, ↔ Mirrors, ⇌ Inverts, ∥ Parallel To, ∼ Adjacent To, → Next, ⇒ Sequence Of, ⇐ Preceded By, ↠ Follows, ↗ Spatially Above, ↘ Spatially Below, ⇝ Symbolically Supports, ⇂ Symbolically Depends, ≠ Contrasts, ⊕ Complements, ⊛ Associated With, ∝ Correlates With, ⇝ Causes, ⇐ Caused By, ∗ Evokes, ≜ Represents, ⋆ Symbolizes, 7→ Refers To, ⊢ Defines, ⊣ Is Defined By, ↷ Transforms To, ↶ Transformed From, ◦ Functions As, |= Interpreted As, ◁ Used With, ⇄ Co-occurs With, ⊗ Synthesizes, ÷ Divides Into, ⊘ Opposes, × Rejects, ¬ Negates, † Destroys, ⊠ Blocks, /∈ Invalidates, ⊬ Contradicts, ⊩ Asserts, ⊨ Provides Evidence, ? Uncertainty, ⚡ Memory, ⇒ Attention, ↶ Self-Reference, ∧ Perspective, ↭ Continuity, ▷◁ Relationality

Return as JSON:
{
  "token": "${token}",
  "relationships": {
    "≡": [{"token": "...", "weight": 0.95}],
    ...
  }
}

Only include relationship types that apply. Leave others empty or omit.`;
      const controller = new AbortController();
      if (signal) {
        signal.addEventListener('abort', () => controller.abort(), { once: true });
      }
      const content = await fetchOpenAI([
        { role: 'system', content: 'You are an HLSF token adjacency analyzer.' },
        { role: 'user', content: prompt },
      ], { signal: controller.signal });
      try {
        const jsonStart = content.indexOf('{');
        const jsonEnd = content.lastIndexOf('}');
        const jsonText = jsonStart >= 0 ? content.slice(jsonStart, jsonEnd + 1) : content;
        const parsed = JSON.parse(jsonText);
        return parsed;
      } catch (err) {
        logError(`Failed to parse adjacency JSON for token "${token}": ${err.message}`);
        return {
          token,
          relationships: {},
          error: 'Failed to parse adjacency JSON.',
          raw: content,
        };
      }
    }

    async function getAdjacencyForTokens(tokens, context, categoryLabel, abortSignal) {
      const statusEntry = logStatus(`⏳ Downloading ${categoryLabel} token weights and adjacencies...`);
      const results = new Map();
      const queue = [...new Set(tokens.map((t) => t.toLowerCase()))];
      const concurrency = 5;
      let active = 0;
      let index = 0;

      return new Promise((resolve) => {
        const processNext = async () => {
          if (abortSignal?.aborted) {
            resolve(results);
            return;
          }
          if (index >= queue.length && active === 0) {
            statusEntry.innerHTML = formatStatusLine(`✅ Completed adjacency retrieval for ${categoryLabel}.`, `${results.size} tokens.`);
            resolve(results);
            return;
          }
          while (active < concurrency && index < queue.length) {
            const token = queue[index++];
            active++;
            (async () => {
              try {
                const cached = getStoredAdjacency(token);
                if (cached) {
                  results.set(token, cached);
                } else if (apiKey) {
                  const adjacency = await requestAdjacency(token, context, abortSignal);
                  if (adjacency) {
                    storeAdjacency(token, adjacency);
                    results.set(token, adjacency);
                  }
                } else {
                  results.set(token, { token, relationships: {}, offline: true });
                }
              } catch (err) {
                logError(`Adjacency fetch failed for ${token}: ${err.message}`);
              } finally {
                active--;
                processNext();
              }
            })();
          }
        };
        processNext();
      });
    }

    function calculateAttentionScores(matrices) {
      for (const entry of matrices.values()) {
        const relationships = entry?.relationships ?? {};
        let weightSum = 0;
        let prioritySum = 0;
        let totalEdges = 0;
        for (const [relation, edges] of Object.entries(relationships)) {
          const priority = RELATIONSHIP_PRIORITIES.get(relation) ?? RELATIONSHIP_PRIORITIES.get(relation.split(' ')[0]) ?? relationshipPriorityFallback;
          if (Array.isArray(edges)) {
            for (const edge of edges) {
              const weight = Number(edge.weight) || 0;
              weightSum += weight * priority;
              prioritySum += priority;
              totalEdges += 1;
            }
          }
        }
        const attention = totalEdges > 0 ? weightSum / totalEdges : 0;
        entry.attention_score = Number(attention.toFixed(3));
        entry.total_relationships = totalEdges;
      }
      return matrices;
    }

    function identifyHighFrequencyHubs(allMatrices) {
      const tokenFrequency = new Map();
      for (const matrix of allMatrices.values()) {
        const relationships = matrix?.relationships ?? {};
        for (const edges of Object.values(relationships)) {
          if (!Array.isArray(edges)) continue;
          for (const edge of edges) {
            const token = edge.token?.toLowerCase();
            if (!token) continue;
            tokenFrequency.set(token, (tokenFrequency.get(token) || 0) + 1);
          }
        }
      }
      const hubs = Array.from(tokenFrequency.entries())
        .filter(([, count]) => count > 5)
        .map(([token, count]) => ({ token, count }));
      hubs.sort((a, b) => b.count - a.count);
      return hubs;
    }

    function identifyCrossRelationshipBridges(allMatrices) {
      const relationshipParticipation = new Map();
      for (const matrix of allMatrices.values()) {
        const relationships = matrix?.relationships ?? {};
        for (const [relationship, edges] of Object.entries(relationships)) {
          if (!Array.isArray(edges)) continue;
          for (const edge of edges) {
            const token = edge.token?.toLowerCase();
            if (!token) continue;
            if (!relationshipParticipation.has(token)) {
              relationshipParticipation.set(token, new Set());
            }
            relationshipParticipation.get(token).add(relationship);
          }
        }
      }
      const bridges = [];
      for (const [token, set] of relationshipParticipation) {
        if (set.size >= 3) {
          bridges.push({ token, relationships: Array.from(set).sort() });
        }
      }
      bridges.sort((a, b) => b.relationships.length - a.relationships.length);
      return bridges;
    }

    function buildMatrixStructure(tokens, matrices, level = 0) {
      const uniqueTokens = [...new Set(tokens.map((t, index) => ({ token: t, index })))];
      const nodeCount = uniqueTokens.length;
      return {
        level,
        n: nodeCount,
        nodes: uniqueTokens.map((item, idx) => {
          const angle = (2 * Math.PI * idx) / Math.max(nodeCount, 1);
          return {
            index: idx,
            token: item.token,
            adjacencyMatrix: matrices.get(item.token.toLowerCase()) ?? null,
            position: { angle, radius: 1 },
          };
        }),
      };
    }

    function summarizeAttention(matrices) {
      const summary = [];
      for (const [token, data] of matrices.entries()) {
        summary.push({ token, attention: data.attention_score ?? 0, total: data.total_relationships ?? 0 });
      }
      summary.sort((a, b) => b.attention - a.attention);
      return summary.slice(0, 20);
    }

    function computeAdjacencyDensity(matrix) {
      let edges = 0;
      for (const data of matrix.values()) {
        const relationships = data?.relationships ?? {};
        for (const edgesList of Object.values(relationships)) {
          if (Array.isArray(edgesList)) {
            edges += edgesList.length;
          }
        }
      }
      const nodes = matrix.size;
      const possibleEdges = nodes > 1 ? nodes * (nodes - 1) : 1;
      const density = edges / possibleEdges;
      return { edges, possibleEdges, density: Number(density.toFixed(3)) };
    }

    function renderTokenEntries(container, matrices, hubs = [], bridges = []) {
      container.innerHTML = '';
      const template = document.getElementById('token-entry-template');
      const hubSet = new Set(hubs.map((hub) => hub.token.toLowerCase()));
      const bridgeSet = new Set(bridges.map((bridge) => bridge.token.toLowerCase()));
      for (const [token, data] of matrices.entries()) {
        const clone = template.content.firstElementChild.cloneNode(true);
        const summary = clone.querySelector('summary');
        const pre = clone.querySelector('pre');
        const attention = data.attention_score ?? 0;
        let badgeClass = 'attention-low';
        if (attention >= 0.8) badgeClass = 'attention-high';
        else if (attention >= 0.5) badgeClass = 'attention-medium';
        if (hubSet.has(token)) badgeClass = 'attention-hub';
        if (bridgeSet.has(token)) badgeClass = 'attention-bridge';

        const relationshipsCount = data.total_relationships ?? 0;
        summary.innerHTML = `<span class="attention-badge ${badgeClass}">${attention.toFixed(3)}</span> <strong>${token}</strong> <span class="status-badge">${relationshipsCount} edges</span>`;
        pre.innerHTML = highlightJSON({ ...data, recursion_level: data.recursion_level ?? 0 });
        clone.addEventListener('toggle', () => {
          if (clone.open) {
            clone.classList.add('expanded');
          } else {
            clone.classList.remove('expanded');
          }
        });
        container.appendChild(clone);
      }
    }

    function exportMatrices(sessionBundle) {
      try {
        const now = new Date();
        const timestamp = now.toISOString().replace(/[:.]/g, '-');
        const blob = new Blob([JSON.stringify(sessionBundle ?? buildCurrentExportBundle(), null, 2)], { type: 'application/json' });
        const url = URL.createObjectURL(blob);
        const link = document.createElement('a');
        link.href = url;
        link.download = `HLSF_Session_${timestamp}.json`;
        document.body.appendChild(link);
        link.click();
        document.body.removeChild(link);
        URL.revokeObjectURL(url);
        logSuccess('Adjacency matrices exported.');
      } catch (err) {
        logError(`Failed to export adjacency matrices: ${err.message}`);
      }
    }

    function buildCurrentExportBundle(context = {}) {
      const { inputPrompt = '', originalResponse = '', revisedResponse = '', emergentThoughts = '', matrices = {}, metadata = {} } = context;
      const storedKeys = Object.keys(localStorage).filter((key) => key.startsWith('hlsf_token_'));
      const storedMatrices = storedKeys.map((key) => {
        try {
          return JSON.parse(localStorage.getItem(key));
        } catch (err) {
          return { key, error: 'Failed to parse stored matrix' };
        }
      });
      return {
        session: {
          timestamp: new Date().toISOString(),
          input_prompt: inputPrompt,
          original_response: originalResponse,
          revised_response: revisedResponse,
          emergent_thoughts: emergentThoughts,
        },
        matrices,
        metadata: {
          ...metadata,
          stored_matrix_count: storedMatrices.length,
        },
        cached_matrices: storedMatrices,
      };
    }

    function persistSessionHistory(entry) {
      try {
        const raw = localStorage.getItem('hlsf_sessions');
        const sessions = raw ? JSON.parse(raw) : [];
        sessions.push(entry);
        while (sessions.length > 50) sessions.shift();
        localStorage.setItem('hlsf_sessions', JSON.stringify(sessions));
      } catch (err) {
        logError(`Failed to persist session history: ${err.message}`);
      }
    }

    async function processPrompt(prompt) {
      if (isProcessing) return;
      isProcessing = true;
      sendBtn.disabled = true;
      commandInput.disabled = true;

      const startTime = performance.now();
      let abortController = new AbortController();

      try {
        const inputTokens = tokenize(prompt);
        if (inputTokens.length === 0) {
          logError('Prompt cannot be empty.');
          return;
        }
        if (inputTokens.length > 100) {
          logError(`Input exceeds 100-token limit (${inputTokens.length}). Please shorten your prompt.`);
          return;
        }
        addLogEntry(`🧮 Input tokens detected: <strong>${inputTokens.length}</strong>`, 'info');

        const llmStatus = logStatus('⏳ Sending prompt to LLM...');
        let initialResponse = '';
        if (apiKey) {
          initialResponse = await fetchOpenAI([
            { role: 'system', content: 'You are an expert assistant that provides clear, concise responses.' },
            { role: 'user', content: prompt },
          ]);
          llmStatus.innerHTML = formatStatusLine('✅ Received response from LLM.', `${countTokens(initialResponse)} tokens.`);
        } else {
          initialResponse = '⚠️ Offline mode: Provide an API key to enable live responses.';
          llmStatus.innerHTML = formatStatusLine('⚠️ Offline mode. Skipped LLM call.', '0 tokens.');
        }

        const responseTokens = tokenize(initialResponse);
        addLogEntry(`🧮 Output tokens detected: <strong>${responseTokens.length}</strong>`, 'info');

        abortController = new AbortController();
        const [inputMatrices, outputMatrices] = await Promise.all([
          getAdjacencyForTokens(inputTokens, prompt, 'input', abortController.signal),
          getAdjacencyForTokens(responseTokens, initialResponse, 'output', abortController.signal),
        ]);

        calculateAttentionScores(inputMatrices);
        calculateAttentionScores(outputMatrices);

        const inputMatrixStructure = buildMatrixStructure(inputTokens, inputMatrices, 0);
        const outputMatrixStructure = buildMatrixStructure(responseTokens, outputMatrices, 0);

        const allMatrices = new Map([...inputMatrices, ...outputMatrices]);
        const hubs = identifyHighFrequencyHubs(allMatrices);
        const bridges = identifyCrossRelationshipBridges(allMatrices);

        const inputDensity = computeAdjacencyDensity(inputMatrices);
        const outputDensity = computeAdjacencyDensity(outputMatrices);
        addLogEntry(`🔗 Input adjacency density: ${inputDensity.density} (${inputDensity.edges}/${inputDensity.possibleEdges})`);
        addLogEntry(`🔗 Output adjacency density: ${outputDensity.density} (${outputDensity.edges}/${outputDensity.possibleEdges})`);

        const highAttentionTokens = summarizeAttention(allMatrices);
        const topAttentionSummary = highAttentionTokens
          .map((item) => `${item.token} (${item.attention.toFixed(2)} · ${item.total})`)
          .join(', ');
        addLogEntry(`🎯 Top attention tokens: ${topAttentionSummary || 'None'}`);

        let synthesis = '';
        if (apiKey) {
          const summaryPayload = `Token relationship analysis:
${JSON.stringify(highAttentionTokens, null, 2)}

High-frequency hubs: ${JSON.stringify(hubs, null, 2)}

Cross-level connections: ${JSON.stringify(bridges, null, 2)}`;
          const synthesisPrompt = `Original prompt: "${prompt}"
Original response: "${initialResponse}"

${summaryPayload}

Synthesize the key conceptual insights revealed by this adjacency analysis. What latent patterns, contradictions, or emergent themes are revealed by the token relationships?`;
          const synthesisStatus = logStatus('⏳ Facilitating hierarchical knowledge synthesis...');
          synthesis = await fetchOpenAI([
            { role: 'system', content: 'You analyze token relationship matrices to extract conceptual insights.' },
            { role: 'user', content: synthesisPrompt },
          ]);
          synthesisStatus.innerHTML = formatStatusLine('✅ Hierarchical knowledge synthesis complete.');
        } else {
          synthesis = 'Offline mode: synthesis unavailable without API access.';
        }

        let thoughtStream = '';
        if (apiKey) {
          const thoughtPrompt = `Based on the following adjacency insights, generate a stream-of-consciousness internal monologue representing the emergent cognitive process:

Key insights: ${synthesis}
Non-local connections: ${JSON.stringify(bridges, null, 2)}
Recursive hubs: ${JSON.stringify(hubs, null, 2)}

Write as a flowing, natural thought process that connects these elements.`;
          const thoughtStatus = logStatus('⏳ Logging emergent thought stream...');
          thoughtStream = await fetchOpenAI([
            { role: 'system', content: 'You create reflective, stream-of-consciousness narratives grounded in provided analytical insights.' },
            { role: 'user', content: thoughtPrompt },
          ]);
          thoughtStatus.innerHTML = formatStatusLine('✅ Emergent thought stream captured.');
        } else {
          thoughtStream = 'Offline mode: thought stream unavailable without API access.';
        }

        let revisedResponse = '';
        if (apiKey) {
          const revisionPrompt = `Original response: "${initialResponse}"

Emergent insights: ${thoughtStream}

Revise the original response by:
1. Removing concepts that were pruned during adjacency analysis (low-weight, disconnected tokens)
2. Incorporating emergent insights more clearly
3. Restructuring for clarity based on hierarchical token relationships
4. Maintaining the original intent but with enhanced coherence

Provide the revised response only, without meta-commentary.`;
          const revisionStatus = logStatus('⏳ Developing revised response output...');
          revisedResponse = await fetchOpenAI([
            { role: 'system', content: 'You refine responses based on adjacency-driven insights.' },
            { role: 'user', content: revisionPrompt },
          ]);
          revisionStatus.innerHTML = formatStatusLine('✅ Revised response generated.');
        } else {
          revisedResponse = initialResponse;
        }

        const processingTime = performance.now() - startTime;
        const finalEntry = document.createElement('div');
        finalEntry.className = 'log-entry final-output';
        finalEntry.innerHTML = `
          <div class="timestamp">${new Date().toLocaleTimeString()}</div>
          <div class="output-divider"></div>
          <div>✓ Processing complete (${(processingTime / 1000).toFixed(1)}s)</div>
          <h3>REVISED RESPONSE:</h3>
          <pre>${revisedResponse}</pre>
          <details>
            <summary>Show original LLM response</summary>
            <pre>${initialResponse}</pre>
          </details>
          <details>
            <summary>Show emergent thought stream</summary>
            <pre>${thoughtStream}</pre>
          </details>
          <details>
            <summary>Explore token adjacency matrices</summary>
            <div class="token-section" id="token-section-input"></div>
            <div class="token-section" id="token-section-output"></div>
            <div class="token-section" id="token-section-hubs"></div>
          </details>
        `;
        logContainer.appendChild(finalEntry);
        logContainer.scrollTo({ top: logContainer.scrollHeight, behavior: 'smooth' });

        const inputSection = finalEntry.querySelector('#token-section-input');
        const outputSection = finalEntry.querySelector('#token-section-output');
        const hubSection = finalEntry.querySelector('#token-section-hubs');

        inputSection.innerHTML = `<h4>📁 Input Tokens (n=${inputMatrixStructure.n})</h4>`;
        outputSection.innerHTML = `<h4>📁 Output Tokens (n=${outputMatrixStructure.n})</h4>`;
        hubSection.innerHTML = `<h4>📁 Recursive Hubs (depth=${recursionDepth})</h4>`;

        const inputWrapper = document.createElement('div');
        const outputWrapper = document.createElement('div');
        const hubWrapper = document.createElement('div');

        renderTokenEntries(inputWrapper, inputMatrices, hubs, bridges);
        renderTokenEntries(outputWrapper, outputMatrices, hubs, bridges);

        for (const hub of hubs) {
          const template = document.getElementById('token-entry-template');
          const clone = template.content.firstElementChild.cloneNode(true);
          const summary = clone.querySelector('summary');
          const pre = clone.querySelector('pre');
          summary.innerHTML = `<span class="attention-badge attention-hub">HUB</span> <strong>${hub.token}</strong> <span class="status-badge">${hub.count} cross-references</span>`;
          pre.innerHTML = highlightJSON(hub);
          hubWrapper.appendChild(clone);
        }

        inputSection.appendChild(inputWrapper);
        outputSection.appendChild(outputWrapper);
        hubSection.appendChild(hubWrapper);

        const sessionEntry = {
          timestamp: new Date().toISOString(),
          input: prompt,
          output: revisedResponse,
          original: initialResponse,
          tokens_processed: inputTokens.length + responseTokens.length,
          recursion_depth: recursionDepth,
        };
        persistSessionHistory(sessionEntry);

        const bundle = buildCurrentExportBundle({
          inputPrompt: prompt,
          originalResponse: initialResponse,
          revisedResponse,
          emergentThoughts: thoughtStream,
          matrices: {
            input_tokens: Array.from(inputMatrices.values()),
            output_tokens: Array.from(outputMatrices.values()),
            recursive_hubs: hubs,
          },
          metadata: {
            total_tokens: sessionEntry.tokens_processed,
            recursion_depth: recursionDepth,
            processing_time_ms: Math.round(processingTime),
          },
        });
        exportMatrices(bundle);
      } catch (err) {
        if (err.name === 'AbortError') {
          logError('Processing aborted.');
        } else {
          logError(err.message || 'An unexpected error occurred.');
        }
      } finally {
        isProcessing = false;
        sendBtn.disabled = false;
        commandInput.disabled = false;
        commandInput.value = '';
        commandInput.focus();
      }
    }

    sendBtn.addEventListener('click', () => {
      const value = commandInput.value.trim();
      if (!value) return;
      addLogEntry(`> ${value}`);
      if (isCommand(value)) {
        handleCommand(value);
      } else {
        processPrompt(value);
      }
    });

    commandInput.addEventListener('keydown', (event) => {
      if (event.key === 'Enter') {
        event.preventDefault();
        sendBtn.click();
      }
    });

    window.addEventListener('beforeunload', () => {
      apiKey = '';
    });

    commandHelp();
  </script>
</body>
</html>
