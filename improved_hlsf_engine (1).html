<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>HLSF Cognition Engine v2.0</title>
  <style>
    :root {
      color-scheme: dark;
      --bg: #0a0a0a;
      --panel: #111;
      --text: #e0e0e0;
      --accent: #00ff88;
      --error: #ff4444;
      --success: #44ff44;
      --warning: #ffd54f;
      --scrollbar: #1f1f1f;
    }

    * { box-sizing: border-box; }

    body {
      margin: 0;
      font-family: 'Fira Code', Consolas, Monaco, 'Courier New', monospace;
      background: var(--bg);
      color: var(--text);
      min-height: 100vh;
      display: flex;
      flex-direction: column;
    }

    #app {
      flex: 1;
      display: flex;
      flex-direction: column;
      max-width: 1200px;
      margin: 0 auto;
      padding: 1.5rem;
      width: 100%;
    }

    #header {
      font-size: 1.3rem;
      font-weight: bold;
      margin-bottom: 1rem;
      color: var(--accent);
      display: flex;
      align-items: center;
      justify-content: space-between;
      flex-wrap: wrap;
      gap: 1rem;
    }

    .header-stats {
      display: flex;
      gap: 1.5rem;
      font-size: 0.9rem;
      font-weight: normal;
    }

    .stat-item {
      display: flex;
      flex-direction: column;
      gap: 0.2rem;
    }

    .stat-label {
      font-size: 0.75rem;
      opacity: 0.6;
    }

    .stat-value {
      font-weight: bold;
      color: var(--accent);
    }

    #log {
      flex: 1;
      background: var(--panel);
      border: 1px solid #222;
      border-radius: 12px;
      padding: 1rem;
      overflow-y: auto;
      display: flex;
      flex-direction: column;
      gap: 1rem;
      box-shadow: 0 0 20px rgba(0, 255, 136, 0.1);
      min-height: 400px;
    }

    #log::-webkit-scrollbar { width: 10px; }
    #log::-webkit-scrollbar-thumb { background: var(--scrollbar); border-radius: 10px; }

    #input-area {
      margin-top: 1rem;
      display: flex;
      gap: 0.75rem;
    }

    #command-input {
      flex: 1;
      padding: 0.75rem 1rem;
      background: var(--panel);
      border: 1px solid #222;
      border-radius: 8px;
      color: var(--text);
      font-size: 1rem;
      transition: border 0.2s ease-in-out, box-shadow 0.2s ease-in-out;
    }

    #command-input:focus {
      outline: none;
      border-color: var(--accent);
      box-shadow: 0 0 0 2px rgba(0, 255, 136, 0.2);
    }

    .button-group {
      display: flex;
      gap: 0.5rem;
    }

    .btn {
      padding: 0.75rem 1.5rem;
      border: none;
      border-radius: 8px;
      font-size: 1rem;
      font-weight: bold;
      cursor: pointer;
      transition: transform 0.15s ease, box-shadow 0.15s ease;
    }

    .btn-primary { background: var(--accent); color: #022d15; }
    .btn-secondary { background: #333; color: var(--text); }

    .btn:hover:not(:disabled) {
      transform: translateY(-1px);
      box-shadow: 0 10px 25px rgba(0, 255, 136, 0.25);
    }

    .btn:disabled {
      opacity: 0.6;
      cursor: not-allowed;
      box-shadow: none;
      transform: none;
    }

    .log-entry {
      border-left: 3px solid var(--accent);
      padding-left: 1rem;
      animation: fadeIn 0.3s ease;
    }

    .log-entry .timestamp {
      font-size: 0.75rem;
      opacity: 0.6;
    }

    .log-entry.status { font-style: italic; }
    .log-entry.error { border-left-color: var(--error); color: var(--error); }
    .log-entry.success { border-left-color: var(--success); color: var(--success); }
    .log-entry.warning { border-left-color: var(--warning); color: var(--warning); }

    .cost-estimate {
      background: rgba(255, 213, 79, 0.1);
      border: 1px solid var(--warning);
      border-radius: 8px;
      padding: 0.75rem;
      margin: 0.5rem 0;
    }

    .section-divider {
      margin: 1.5rem 0 0.5rem 0;
      border-top: 2px solid #222;
      padding-top: 1rem;
    }

    .section-title {
      font-size: 1.1rem;
      font-weight: bold;
      color: var(--accent);
      margin-bottom: 0.5rem;
    }

    .thought-stream {
      background: rgba(0, 255, 136, 0.05);
      border: 1px solid rgba(0, 255, 136, 0.2);
      border-radius: 8px;
      padding: 1rem;
      font-style: italic;
      line-height: 1.6;
    }

    .adjacency-insight {
      background: rgba(255, 213, 79, 0.05);
      border: 1px solid rgba(255, 213, 79, 0.2);
      border-radius: 8px;
      padding: 0.75rem;
      margin: 0.5rem 0;
      font-size: 0.9rem;
    }

    .token-highlight {
      background: rgba(0, 255, 136, 0.2);
      padding: 0.1rem 0.3rem;
      border-radius: 3px;
      font-weight: bold;
    }

    .final-output {
      border-left: 3px solid var(--success);
      padding: 1rem;
      background: rgba(68, 255, 68, 0.05);
      border-radius: 8px;
    }

    .final-output h3 {
      margin-top: 0;
      color: var(--success);
    }

    details {
      background: rgba(255, 255, 255, 0.02);
      border: 1px solid #222;
      border-radius: 8px;
      padding: 0.5rem 0.75rem;
      margin: 0.5rem 0;
      transition: border 0.2s ease;
    }

    details[open] {
      border-color: var(--accent);
      box-shadow: 0 0 0 1px rgba(0, 255, 136, 0.25);
    }

    summary {
      cursor: pointer;
      display: flex;
      align-items: center;
      gap: 0.5rem;
      list-style: none;
      font-weight: 600;
      padding: 0.3rem 0;
    }

    summary::-webkit-details-marker { display: none; }

    pre {
      white-space: pre-wrap;
      word-wrap: break-word;
      background: rgba(0, 0, 0, 0.3);
      padding: 0.75rem;
      border-radius: 6px;
      font-size: 0.9rem;
      line-height: 1.5;
      margin: 0.5rem 0;
    }

    .modal {
      position: fixed;
      inset: 0;
      backdrop-filter: blur(8px);
      background: rgba(0, 0, 0, 0.7);
      display: flex;
      align-items: center;
      justify-content: center;
      z-index: 999;
    }

    .modal.hidden { display: none; }

    .modal-content {
      background: #111;
      border: 1px solid var(--accent);
      border-radius: 12px;
      padding: 2rem;
      width: min(420px, 90vw);
      display: flex;
      flex-direction: column;
      gap: 1rem;
      box-shadow: 0 20px 40px rgba(0, 0, 0, 0.4);
    }

    .modal-content h2 { margin: 0; color: var(--accent); }

    .modal-content input {
      padding: 0.75rem 1rem;
      border-radius: 8px;
      border: 1px solid #222;
      background: #0c0c0c;
      color: var(--text);
      font-size: 1rem;
    }

    .modal-actions {
      display: flex;
      justify-content: flex-end;
      gap: 0.75rem;
    }

    .pill-button {
      border-radius: 999px;
      border: none;
      padding: 0.5rem 1.4rem;
      font-weight: bold;
      cursor: pointer;
      transition: transform 0.15s ease, box-shadow 0.15s ease;
    }

    .pill-button.primary { background: var(--accent); color: #022d15; }
    .pill-button.secondary { background: transparent; border: 1px solid #333; color: var(--text); }

    .pill-button:not(:disabled):hover {
      transform: translateY(-1px);
      box-shadow: 0 10px 25px rgba(0, 255, 136, 0.18);
    }

    .spinner {
      width: 14px;
      height: 14px;
      border-radius: 50%;
      border: 2px solid rgba(0, 255, 136, 0.15);
      border-top-color: var(--accent);
      animation: spin 0.8s linear infinite;
    }

    .processing-indicator {
      display: inline-flex;
      align-items: center;
      gap: 0.35rem;
    }

    @media (max-width: 720px) {
      #app { padding: 1rem; }
      #header { flex-direction: column; align-items: flex-start; }
      .header-stats { flex-direction: column; gap: 0.5rem; }
      #input-area { flex-direction: column; }
      .button-group { flex-direction: column; }
      .btn { width: 100%; }
    }

    @keyframes fadeIn {
      from { opacity: 0; transform: translateY(6px); }
      to { opacity: 1; transform: translateY(0); }
    }

    @keyframes spin {
      from { transform: rotate(0deg); }
      to { transform: rotate(360deg); }
    }
  </style>
</head>
<body>
  <div id="api-modal" class="modal">
    <div class="modal-content" role="dialog" aria-modal="true">
      <h2>Enter OpenAI API Key</h2>
      <p>Provide your OpenAI API key (sk-...) to begin using the HLSF Cognition Engine.</p>
      <input id="api-key-input" type="password" placeholder="sk-..." />
      <div class="modal-actions">
        <button id="api-cancel" class="pill-button secondary">Continue offline</button>
        <button id="api-confirm" class="pill-button primary">Save key</button>
      </div>
      <small style="opacity:0.65">⚠️ Note: Download this HTML file and run locally for API calls to work.</small>
    </div>
  </div>

  <div id="app">
    <div id="header">
      <div>HLSF Cognition Engine v2.0</div>
      <div class="header-stats">
        <div class="stat-item">
          <span class="stat-label">Cache Hit Rate</span>
          <span class="stat-value" id="cache-hit-rate">—</span>
        </div>
        <div class="stat-item">
          <span class="stat-label">Cached Tokens</span>
          <span class="stat-value" id="cached-tokens">—</span>
        </div>
        <div class="stat-item">
          <span class="stat-label">Session Cost</span>
          <span class="stat-value" id="session-cost">$0.00</span>
        </div>
      </div>
    </div>
    <div id="log"></div>
    <div id="input-area">
      <input id="command-input" type="text" placeholder="> Enter a prompt or /command" maxlength="600" autocomplete="off" />
      <div class="button-group">
        <button id="cancel-btn" class="btn btn-secondary" style="display: none;">Cancel</button>
        <button id="send-btn" class="btn btn-primary">Send</button>
      </div>
    </div>
  </div>

  <script>
    // ============================================
    // CONFIGURATION
    // ============================================
    const CONFIG = {
      MAX_TOKENS_PER_PROMPT: 100,
      MAX_CONCURRENCY: 5,
      MAX_RETRY_ATTEMPTS: 3,
      RETRY_BASE_DELAY_MS: 500,
      DEFAULT_MODEL: 'gpt-4o-mini',
      ESTIMATED_COST_PER_API_CALL: 0.02,
    };

    const RELATIONSHIP_PRIORITIES = new Map([
      ['≡', 1.0], ['⊃', 1.0], ['⊂', 0.8], ['≈', 0.7], ['∈', 0.9], ['∋', 0.9],
      ['⊤', 0.9], ['⊥', 0.9], ['⊏', 0.8], ['⊐', 0.8], ['↔', 0.7], ['⇌', 0.7],
      ['∥', 0.6], ['∼', 0.5], ['→', 0.5], ['⇒', 0.5], ['⇐', 0.5], ['↠', 0.5],
      ['↗', 0.4], ['↘', 0.4], ['⇝', 1.0], ['⇂', 0.7], ['≠', 0.8], ['⊕', 0.8],
      ['⊛', 0.7], ['∝', 0.7], ['⇝ Causes', 1.0], ['⇐ Caused By', 0.9],
      ['∗', 0.7], ['≜', 0.9], ['⋆', 0.8], ['7→', 0.7], ['⊢', 0.9], ['⊣', 0.9],
      ['↷', 0.8], ['↶', 0.8], ['◦', 0.9], ['|=', 0.9], ['◁', 0.6], ['⇄', 0.6],
      ['⊗', 0.9], ['÷', 0.7], ['⊘', 0.8], ['×', 0.8], ['¬', 0.8], ['†', 0.8],
      ['⊠', 0.8], ['/∈', 0.8], ['⊬', 0.8], ['⊩', 0.9], ['⊨', 0.9], ['?', 0.5],
      ['⚡', 0.7], ['⇒ Attention', 0.7], ['↶ Self-Reference', 0.7], ['∧', 0.6],
      ['↭', 0.6], ['▷◁', 0.6]
    ]);

    // ============================================
    // STATE
    // ============================================
    const state = {
      apiKey: '',
      isProcessing: false,
      sessionStats: {
        totalApiCalls: 0,
        totalCacheHits: 0,
        totalCostCents: 0,
      }
    };

    let currentAbortController = null;

    // ============================================
    // DOM ELEMENTS
    // ============================================
    const elements = {
      log: document.getElementById('log'),
      input: document.getElementById('command-input'),
      sendBtn: document.getElementById('send-btn'),
      cancelBtn: document.getElementById('cancel-btn'),
      apiModal: document.getElementById('api-modal'),
      apiKeyInput: document.getElementById('api-key-input'),
      apiConfirmBtn: document.getElementById('api-confirm'),
      apiCancelBtn: document.getElementById('api-cancel'),
      cacheHitRate: document.getElementById('cache-hit-rate'),
      cachedTokens: document.getElementById('cached-tokens'),
      sessionCost: document.getElementById('session-cost'),
    };

    // ============================================
    // UTILITIES
    // ============================================
    function sanitize(text) {
      const div = document.createElement('div');
      div.textContent = text;
      return div.innerHTML;
    }

    function tokenize(text) {
      if (!text) return [];
      return text.trim()
        .split(/[^\p{L}\p{N}\-']+/u)
        .filter(Boolean)
        .map(t => t.toLowerCase());
    }

    function formatCurrency(cents) {
      return `$${(cents / 100).toFixed(2)}`;
    }

    function getCachedTokenCount() {
      return Object.keys(localStorage).filter(k => k.startsWith('hlsf_token_')).length;
    }

    // ============================================
    // LOGGING
    // ============================================
    function addLog(content, type = 'info') {
      const entry = document.createElement('div');
      entry.className = `log-entry ${type}`;
      entry.innerHTML = `<div class="timestamp">${new Date().toLocaleTimeString()}</div>${content}`;
      elements.log.appendChild(entry);
      elements.log.scrollTop = elements.log.scrollHeight;
      return entry;
    }

    function logStatus(msg) { return addLog(`<div class="processing-indicator"><span class="spinner"></span>${msg}</div>`, 'status'); }
    function logError(msg) { return addLog(`🔴 ${sanitize(msg)}`, 'error'); }
    function logSuccess(msg) { return addLog(`✅ ${sanitize(msg)}`, 'success'); }
    function logWarning(msg) { return addLog(`⚠️ ${sanitize(msg)}`, 'warning'); }

    // ============================================
    // STATS
    // ============================================
    function updateStats() {
      const { totalApiCalls, totalCacheHits, totalCostCents } = state.sessionStats;
      const total = totalApiCalls + totalCacheHits;
      const hitRate = total > 0 ? ((totalCacheHits / total) * 100).toFixed(1) + '%' : '—';
      
      elements.cacheHitRate.textContent = hitRate;
      elements.cachedTokens.textContent = getCachedTokenCount();
      elements.sessionCost.textContent = formatCurrency(totalCostCents);
    }

    // ============================================
    // CACHE
    // ============================================
    function getCacheKey(token) { return `hlsf_token_${token.toLowerCase()}`; }

    function getFromCache(token) {
      try {
        const raw = localStorage.getItem(getCacheKey(token));
        if (!raw) return null;
        state.sessionStats.totalCacheHits++;
        updateStats();
        return JSON.parse(raw);
      } catch { return null; }
    }

    function saveToCache(token, data) {
      try {
        localStorage.setItem(getCacheKey(token), JSON.stringify({
          ...data,
          cached_at: new Date().toISOString()
        }));
      } catch (err) {
        if (err.name === 'QuotaExceededError') {
          logWarning('Cache full. Use /reset to clear old data.');
        }
      }
    }

    // ============================================
    // OPENAI API
    // ============================================
    async function callOpenAI(messages, options = {}) {
      if (!state.apiKey) throw new Error('No API key configured');

      const body = {
        model: options.model || CONFIG.DEFAULT_MODEL,
        messages,
        max_tokens: options.max_tokens || 1000,
        temperature: options.temperature || 0.7,
      };

      let attempt = 0;
      while (attempt < CONFIG.MAX_RETRY_ATTEMPTS) {
        if (currentAbortController?.signal.aborted) {
          const error = new Error('Cancelled');
          error.name = 'AbortError';
          throw error;
        }

        attempt++;
        try {
          const response = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: {
              'Content-Type': 'application/json',
              'Authorization': `Bearer ${state.apiKey}`,
            },
            body: JSON.stringify(body),
          });

          if (response.status === 429 && attempt < CONFIG.MAX_RETRY_ATTEMPTS) {
            await new Promise(r => setTimeout(r, CONFIG.RETRY_BASE_DELAY_MS * Math.pow(2, attempt - 1)));
            continue;
          }

          if (!response.ok) {
            const errorText = await response.text();
            let errorMessage = `API error (${response.status})`;
            
            try {
              const errorData = JSON.parse(errorText);
              if (errorData.error?.message) errorMessage = errorData.error.message;
            } catch (e) {
              if (errorText) errorMessage = errorText;
            }
            
            if (response.status === 401) errorMessage = 'Invalid API key';
            else if (response.status === 403) errorMessage = 'Access forbidden - check billing setup';
            else if (response.status === 429) errorMessage = 'Rate limit exceeded';
            
            throw new Error(errorMessage);
          }

          const data = await response.json();
          state.sessionStats.totalApiCalls++;
          state.sessionStats.totalCostCents += Math.ceil(CONFIG.ESTIMATED_COST_PER_API_CALL * 100);
          updateStats();

          return data.choices?.[0]?.message?.content?.trim() || '';
        } catch (err) {
          if (err.name === 'AbortError') throw err;
          if (err.message === 'Failed to fetch') {
            throw new Error('Network error - check connection or download HTML to run locally');
          }
          if (attempt === CONFIG.MAX_RETRY_ATTEMPTS) throw err;
        }
      }
    }

    // ============================================
    // ADJACENCY
    // ============================================
    async function fetchAdjacency(token, context) {
      if (currentAbortController?.signal.aborted) {
        throw new Error('AbortError');
      }

      const cached = getFromCache(token);
      if (cached) return { ...cached, cache_hit: true };

      if (!state.apiKey) return { token, relationships: {}, offline: true };

      const prompt = `Token: "${token}"
Context: "${context}"

For this token, identify the most relevant adjacent tokens across relationship types. For each that applies, provide related tokens with weights 0.01-1.00.

Relationship types: ≡ Identity, ⊃ Contains, ⊂ Is Contained By, ≈ Variant, ∈ Is Instance Of, ∋ Has Instance, ⊤ Is Type Of, ⊥ Has Type, ⊏ Part Of, ⊐ Composes, ↔ Mirrors, ⇌ Inverts, ∥ Parallel To, ∼ Adjacent To, → Next, ⇒ Sequence Of, ⇐ Preceded By, ↠ Follows, ↗ Spatially Above, ↘ Spatially Below, ⇝ Symbolically Supports, ⇂ Symbolically Depends, ≠ Contrasts, ⊕ Complements, ⊛ Associated With, ∝ Correlates With, ⇝ Causes, ⇐ Caused By, ∗ Evokes, ≜ Represents, ⋆ Symbolizes, 7→ Refers To, ⊢ Defines, ⊣ Is Defined By, ↷ Transforms To, ↶ Transformed From, ◦ Functions As, |= Interpreted As, ◁ Used With, ⇄ Co-occurs With, ⊗ Synthesizes, ÷ Divides Into, ⊘ Opposes, × Rejects, ¬ Negates, † Destroys, ⊠ Blocks, /∈ Invalidates, ⊬ Contradicts, ⊩ Asserts, ⊨ Provides Evidence, ? Uncertainty, ⚡ Memory, ⇒ Attention, ↶ Self-Reference, ∧ Perspective, ↭ Continuity, ▷◁ Relationality

Return JSON: {"token": "${token}", "relationships": {"≡": [{"token": "...", "weight": 0.95}], ...}}`;

      const content = await callOpenAI([
        { role: 'system', content: 'You are an HLSF token adjacency analyzer.' },
        { role: 'user', content: prompt },
      ]);

      try {
        const jsonStart = content.indexOf('{');
        const jsonEnd = content.lastIndexOf('}');
        const parsed = JSON.parse(content.slice(jsonStart, jsonEnd + 1));
        saveToCache(token, parsed);
        return { ...parsed, cache_hit: false };
      } catch {
        return { token, relationships: {}, error: 'Parse failed' };
      }
    }

    async function batchFetchAdjacencies(tokens, context, label) {
      const status = logStatus(`⏳ Fetching ${label} adjacencies...`);
      const results = new Map();
      const unique = [...new Set(tokens)];
      
      let processed = 0;
      for (let i = 0; i < unique.length; i += CONFIG.MAX_CONCURRENCY) {
        if (currentAbortController?.signal.aborted) {
          status.innerHTML = `⚠️ ${label} cancelled (${processed}/${unique.length})`;
          break;
        }
        
        const batch = unique.slice(i, i + CONFIG.MAX_CONCURRENCY);
        const settled = await Promise.allSettled(batch.map(t => fetchAdjacency(t, context)));
        
        settled.forEach((result, idx) => {
          if (result.status === 'fulfilled') {
            results.set(batch[idx], result.value);
          }
        });
        
        processed += batch.length;
        status.innerHTML = `⏳ ${label} (${processed}/${unique.length})`;
      }
      
      const hits = Array.from(results.values()).filter(r => r.cache_hit).length;
      status.innerHTML = `✅ ${label} complete (${hits} cached, ${results.size - hits} new)`;
      return results;
    }

    function calculateAttention(matrices) {
      for (const entry of matrices.values()) {
        let weightSum = 0, totalEdges = 0;
        const rels = entry?.relationships || {};
        
        for (const [rel, edges] of Object.entries(rels)) {
          const priority = RELATIONSHIP_PRIORITIES.get(rel) || 0.3;
          if (Array.isArray(edges)) {
            edges.forEach(edge => {
              weightSum += (edge.weight || 0) * priority;
              totalEdges++;
            });
          }
        }
        
        entry.attention_score = totalEdges > 0 ? Number((weightSum / totalEdges).toFixed(3)) : 0;
        entry.total_relationships = totalEdges;
      }
      return matrices;
    }

    function summarizeAttention(matrices) {
      const summary = [];
      for (const [token, data] of matrices.entries()) {
        summary.push({ 
          token, 
          attention: data.attention_score || 0, 
          total: data.total_relationships || 0 
        });
      }
      return summary.sort((a, b) => b.attention - a.attention).slice(0, 10);
    }

    function formatTopTokens(topTokens) {
      return topTokens.map(t => 
        `<span class="token-highlight">${t.token}</span> (${t.attention.toFixed(2)})`
      ).join(', ');
    }

    function extractKeyRelationships(matrices) {
      const relationships = [];
      let count = 0;
      for (const [token, data] of matrices.entries()) {
        if (count >= 5) break;
        const rels = data?.relationships || {};
        for (const [rel, edges] of Object.entries(rels)) {
          if (!Array.isArray(edges) || edges.length === 0) continue;
          const topEdge = edges.sort((a, b) => b.weight - a.weight)[0];
          relationships.push(`${token} ${rel} ${topEdge.token} (${topEdge.weight.toFixed(2)})`);
          count++;
          if (count >= 5) break;
        }
      }
      return relationships;
    }

    // ============================================
    // COMMANDS
    // ============================================
    function isCommand(input) { return input.startsWith('/'); }

    async function handleCommand(cmd) {
      const [command] = cmd.slice(1).split(/\s+/);
      
      switch (command.toLowerCase()) {
        case 'clear':
          elements.log.innerHTML = '';
          logSuccess('Log cleared');
          break;
        case 'reset':
          if (confirm('Clear all cached data?')) {
            const keys = Object.keys(localStorage).filter(k => k.startsWith('hlsf_token_'));
            keys.forEach(k => localStorage.removeItem(k));
            updateStats();
            logSuccess(`Cleared ${keys.length} tokens`);
          }
          break;
        case 'stats':
          const { totalApiCalls, totalCacheHits, totalCostCents } = state.sessionStats;
          const total = totalApiCalls + totalCacheHits;
          const hitRate = total > 0 ? ((totalCacheHits / total) * 100).toFixed(1) : 0;
          addLog(`<strong>Session Stats:</strong><br>
            • Requests: ${total}<br>
            • Cache hits: ${totalCacheHits} (${hitRate}%)<br>
            • API calls: ${totalApiCalls}<br>
            • Cost: ${formatCurrency(totalCostCents)}<br>
            • Cached tokens: ${getCachedTokenCount()}`);
          break;
        case 'help':
          addLog(`<strong>Commands:</strong><br>
            /clear - Clear log<br>
            /reset - Clear cache<br>
            /stats - Session statistics<br>
            /help - Show commands`);
          break;
        default:
          logError(`Unknown: ${command}`);
      }
    }

    // ============================================
    // MAIN PROCESSING
    // ============================================
    async function processPrompt(prompt) {
      if (state.isProcessing) return;
      
      state.isProcessing = true;
      currentAbortController = new AbortController();
      elements.sendBtn.disabled = true;
      elements.cancelBtn.style.display = 'inline-block';
      elements.input.disabled = true;

      const startTime = performance.now();

      try {
        const tokens = tokenize(prompt);
        if (tokens.length === 0) {
          logError('Prompt cannot be empty');
          return;
        }
        if (tokens.length > CONFIG.MAX_TOKENS_PER_PROMPT) {
          logError(`Exceeds ${CONFIG.MAX_TOKENS_PER_PROMPT} token limit (${tokens.length})`);
          return;
        }

        const estimatedCalls = tokens.length * 2 + 3;
        const estimatedCost = estimatedCalls * CONFIG.ESTIMATED_COST_PER_API_CALL;
        addLog(`<div class="cost-estimate">
          📊 <strong>Estimate:</strong> ${tokens.length} tokens, ~${estimatedCalls} API calls, ~${formatCurrency(Math.ceil(estimatedCost * 100))}
        </div>`);

        // Step 1: Initial response
        let initialResponse = '';
        if (state.apiKey) {
          const s1 = logStatus('⏳ Generating initial response...');
          initialResponse = await callOpenAI([
            { role: 'system', content: 'You are an expert assistant.' },
            { role: 'user', content: prompt },
          ]);
          s1.innerHTML = `✅ Initial response generated`;
        } else {
          initialResponse = '⚠️ Offline mode';
          logWarning('Skipped (offline)');
        }

        // Step 2: Adjacency analysis
        const responseTokens = tokenize(initialResponse);
        const [inputMatrices, outputMatrices] = await Promise.all([
          batchFetchAdjacencies(tokens, prompt, 'input'),
          batchFetchAdjacencies(responseTokens, initialResponse, 'output'),
        ]);

        calculateAttention(inputMatrices);
        calculateAttention(outputMatrices);

        const allMatrices = new Map([...inputMatrices, ...outputMatrices]);
        const topTokens = summarizeAttention(allMatrices);
        const keyRels = extractKeyRelationships(allMatrices);

        addLog(`<div class="adjacency-insight">
          <strong>🎯 High Attention:</strong> ${formatTopTokens(topTokens)}
        </div>
        <div class="adjacency-insight">
          <strong>🔗 Key Relationships:</strong><br>
          ${keyRels.map(r => `• ${r}`).join('<br>')}
        </div>`);

        // Step 3: Thought stream
        let thoughtStream = '';
        if (state.apiKey) {
          const s2 = logStatus('⏳ Synthesizing thought stream...');
          thoughtStream = await callOpenAI([
            { role: 'system', content: 'You create reflective thought streams from analytical insights.' },
            { role: 'user', content: `Based on these adjacency insights, generate a stream-of-consciousness internal monologue:\n\nTop tokens: ${JSON.stringify(topTokens)}\nRelationships: ${keyRels.join('; ')}\n\nWrite as flowing natural thought connecting these elements.` },
          ]);
          s2.innerHTML = '✅ Thought stream captured';
          
          addLog(`<div class="section-divider"></div>
            <div class="section-title">💭 Emergent Thought Stream</div>
            <div class="thought-stream">${sanitize(thoughtStream)}</div>`);
        }

        // Step 4: Refined response
        let refinedResponse = initialResponse;
        if (state.apiKey) {
          const s3 = logStatus('⏳ Refining response...');
          refinedResponse = await callOpenAI([
            { role: 'system', content: 'You refine responses based on adjacency insights.' },
            { role: 'user', content: `Original: "${initialResponse}"\n\nInsights: ${thoughtStream}\n\nRevise by: 1) Incorporating emergent insights 2) Restructuring based on token relationships 3) Enhancing coherence. Provide revised response only.` },
          ]);
          s3.innerHTML = '✅ Response refined';
        }

        // Display final output
        const time = ((performance.now() - startTime) / 1000).toFixed(1);
        addLog(`<div class="section-divider"></div>
          <div class="final-output">
            <h3>✨ REFINED RESPONSE</h3>
            <pre>${sanitize(refinedResponse)}</pre>
            
            <details>
              <summary>Compare with original response</summary>
              <pre>${sanitize(initialResponse)}</pre>
            </details>
            
            <details>
              <summary>View adjacency data (${allMatrices.size} tokens)</summary>
              <pre>${JSON.stringify(Array.from(allMatrices.entries()).slice(0, 5), null, 2)}</pre>
            </details>
          </div>
        `);
        
        logSuccess(`Processing complete (${time}s)`);

      } catch (err) {
        if (err.name === 'AbortError' || err.message === 'AbortError') {
          logWarning('Processing cancelled');
        } else {
          logError(err.message || 'Processing failed');
          console.error(err);
        }
      } finally {
        state.isProcessing = false;
        currentAbortController = null;
        elements.sendBtn.disabled = false;
        elements.cancelBtn.style.display = 'none';
        elements.input.disabled = false;
        elements.input.value = '';
        elements.input.focus();
      }
    }

    // ============================================
    // EVENTS
    // ============================================
    elements.apiConfirmBtn.addEventListener('click', () => {
      const key = elements.apiKeyInput.value.trim();
      if (!key.startsWith('sk-')) {
        logError('Invalid API key format');
        return;
      }
      state.apiKey = key;
      elements.apiModal.classList.add('hidden');
      logSuccess('API key configured');
    });

    elements.apiCancelBtn.addEventListener('click', () => {
      elements.apiModal.classList.add('hidden');
      logWarning('Offline mode - limited functionality');
    });

    elements.sendBtn.addEventListener('click', () => {
      const input = elements.input.value.trim();
      if (!input) return;
      
      addLog(`> ${sanitize(input)}`);
      
      if (isCommand(input)) {
        handleCommand(input);
        elements.input.value = '';
      } else {
        processPrompt(input);
      }
    });

    elements.cancelBtn.addEventListener('click', () => {
      if (currentAbortController) {
        currentAbortController.abort();
        logWarning('Cancelling...');
      }
    });

    elements.input.addEventListener('keydown', (e) => {
      if (e.key === 'Enter') {
        e.preventDefault();
        elements.sendBtn.click();
      }
    });

    // ============================================
    // INIT
    // ============================================
    window.addEventListener('beforeunload', () => {
      state.apiKey = '';
    });

    updateStats();
    addLog(`<strong>🧠 HLSF Cognition Engine v2.0</strong><br><br>
      This engine performs:<br>
      1. Token adjacency mapping (50 relationship types)<br>
      2. Attention score calculation<br>
      3. Emergent thought stream synthesis<br>
      4. Response refinement based on insights<br><br>
      Type a prompt or /help for commands.<br>
      <small>⚠️ Note: Download HTML and run locally for API calls to work.</small>
    `);
    elements.input.focus();
  </script>
</body>
</html>